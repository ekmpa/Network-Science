# -*- coding: utf-8 -*-
"""netw-sci-explorer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OUOdlF2RjBJ_kcfcqpuNlUSXoilpcsbX
"""

import scipy as sp
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import networkx as nx
import random
import pickle
import community
from community import community_louvain
from networkx.algorithms.cuts import conductance
from sklearn.preprocessing import MinMaxScaler
from sklearn.cluster import SpectralClustering
from sklearn.metrics import normalized_mutual_info_score, adjusted_rand_score
from networkx.algorithms.community import girvan_newman

from google.colab import drive
drive.mount('/content/drive')

def make_from_gml(file_path):
  G = nx.read_gml(file_path, label='id')
  return G


def make_from_gml_multi(file_path):
  G = nx.read_gml(file_path, label='id')

  if nx.is_directed(G):
        G = G.to_undirected()

  return G

def sample_graph(G, ratio):
  amount = round(ratio * G.number_of_nodes())
  sampled_nodes = random.sample(list(G.nodes), amount)
  sampled_graph = G.subgraph(sampled_nodes)

  return sampled_graph

def make_graph(file_path):  # this is for .graph files
  with open(file_path, "rb") as f:
        graph_dict = pickle.load(f)

  G = nx.from_dict_of_lists(graph_dict)

  return G

def load_labels(file_path): # from .ally file
    y_data = np.load(file_path, allow_pickle = True)
    labels = np.argmax(y_data, axis=1)
    return labels

def get_labeled_subgraph(graph, labels):
    labeled_nodes = list(range(len(labels)))
    return graph.subgraph(labeled_nodes).copy()

def louvain_clustering(G):
    partition = community_louvain.best_partition(G)
    return partition

def spectral_clustering(G, n_clusters=5):
    AM = nx.to_numpy_array(G)  # convert to AM
    clustering = SpectralClustering(n_clusters=n_clusters, affinity='precomputed', random_state=1).fit(AM)
    labels = {node: label for node, label in zip(G.nodes(), clustering.labels_)}
    return labels

def girvan_newman_clustering(G, num_communities=3):
    if not nx.is_connected(G):
        largest_cc = max(nx.connected_components(G), key=len)
        G = G.subgraph(largest_cc).copy()

    comp = girvan_newman(G)

    for i, partition in enumerate(comp):
        if i == num_communities - 2:  # because first split is 2 communities, second split is 3, etc.
            communities = [list(c) for c in partition]  # convert tuple of sets to list of lists
            break

    # convert into node-cluster dictionary
    community_labels = {}
    for cluster_id, community in enumerate(communities):
        for node in community:
            community_labels[node] = cluster_id

    return community_labels

def compute_modularity(G, partition):
    communities = {c: [] for c in set(partition.values())}
    for node, comm in partition.items():
        communities[comm].append(node)

    community_list = list(communities.values())
    return nx.algorithms.community.quality.modularity(G, community_list)

def compute_conductance(G, clusters):
    conductance_values = []

    # extract unique communities
    for community in set(clusters.values()):
        nodes_in_community = {node for node in clusters if clusters[node] == community}

        # ensure the community is valid (not empty)
        if len(nodes_in_community) > 1 and len(nodes_in_community) < len(G):
            conductance_values.append(conductance(G, nodes_in_community))

    return sum(conductance_values) / len(conductance_values) if conductance_values else 0.0

def plot_graph(G, clusters, title):
    plt.figure(figsize=(8, 6))
    pos = nx.spring_layout(G)

    unique_clusters = set(clusters.values())
    colors = plt.cm.jet(range(0, 256, int(256 / len(unique_clusters))))
    color_map = {cluster: colors[i] for i, cluster in enumerate(unique_clusters)}

    node_colors = [color_map[clusters[node]] for node in G.nodes()]

    nx.draw(G, pos, node_color=node_colors, with_labels=True, node_size=500, edge_color='gray')
    plt.title(title)
    plt.show()

def get_and_eval_clustering(G):
  louvain_clusters = louvain_clustering(G)
  n_clusters = max(set(louvain_clusters.values())) + 1

  if(nx.is_connected(G)):

    # spectral
    spectral_clusters = spectral_clustering(G, n_clusters=n_clusters)
    spectral_modularity = compute_modularity(G, spectral_clusters)
    spectral_conductance = compute_conductance(G, spectral_clusters)

    # girvan-newman
    girvan_clusters = girvan_newman_clustering(G, num_communities=n_clusters)
    girvan_modularity = compute_modularity(G, girvan_clusters)
    girvan_conductance = compute_conductance(G, girvan_clusters)

  else:

    # spectral
    largest_cc = max(nx.connected_components(G), key=len)
    G_lcc = G.subgraph(largest_cc).copy()
    spectral_clusters = spectral_clustering(G_lcc, n_clusters=n_clusters)
    spectral_modularity = compute_modularity(G_lcc, spectral_clusters)
    spectral_conductance = compute_conductance(G_lcc, spectral_clusters)

    # girvan-newman
    girvan_clusters = girvan_newman_clustering(G_lcc, num_communities=n_clusters)
    girvan_modularity = compute_modularity(G_lcc, girvan_clusters)
    girvan_conductance = compute_conductance(G_lcc, girvan_clusters)

  # louvain
  louvain_modularity = compute_modularity(G, louvain_clusters)
  louvain_conductance = compute_conductance(G, louvain_clusters)

  print(f"Louvain Modularity: {louvain_modularity:.4f}")
  print(f"Louvain Conductance: {louvain_conductance:.4f}")

  print(f"Spectral Modularity: {spectral_modularity:.4f}")
  print(f"Spectral Conductance: {spectral_conductance:.4f}")

  print(f"Girvan-Newman Modularity: {girvan_modularity:.4f}")
  print(f"Girvan-Newman Conductance: {girvan_conductance:.4f}")


  plot_graph(G, louvain_clusters, "Louvain Clustering")
  plot_graph(G, spectral_clusters, "Spectral Clustering")
  plot_graph(G, girvan_clusters, "Girvan-Newman Clustering")

"""### Importing real-classic graphs:"""

strike_graph = make_from_gml("/content/drive/MyDrive/cs-projects/centrality-data/strike.gml")
karate_graph = make_from_gml("/content/drive/MyDrive/cs-projects/centrality-data/karate.gml")
polblogs_graph = make_from_gml_multi("/content/drive/MyDrive/cs-projects/centrality-data/polblogs.gml")  # This one has duplicated edges so need to add "multigraph 1" at the top of the .gml file.
sample_polblog = sample_graph(polblogs_graph, 0.25)
polbooks_graph = make_from_gml("/content/drive/MyDrive/cs-projects/centrality-data/polbooks.gml")
football_graph = make_from_gml("/content/drive/MyDrive/cs-projects/centrality-data/polbooks.gml")

real_classic_graph = [strike_graph, karate_graph, sample_polblog, polbooks_graph, football_graph]

"""### Importing real-node-label graphs:"""

# load true labels
citeseer_labels = load_labels("/content/drive/MyDrive/cs-projects/centrality-data/ind.citeseer.ally")
cora_labels = load_labels("/content/drive/MyDrive/cs-projects/centrality-data/ind.cora.ally")
pubmed_labels = load_labels("/content/drive/MyDrive/cs-projects/centrality-data/ind.pubmed.ally")

citeseer_graph = make_graph("/content/drive/MyDrive/cs-projects/centrality-data/ind.citeseer.graph")
cora_graph = make_graph("/content/drive/MyDrive/cs-projects/centrality-data/ind.cora.graph")
pubmed_graph = make_graph("/content/drive/MyDrive/cs-projects/centrality-data/ind.pubmed.graph")

pubmed_sampled = sample_graph(pubmed_graph, 0.25)

real_node_graph = [citeseer_graph, cora_graph, pubmed_sampled]

real_node_graphs = [
    (citeseer_graph, citeseer_labels, "Citeseer"),
    (cora_graph, cora_labels, "Cora"),
    (pubmed_sampled, pubmed_labels, "PubMed")
]

get_and_eval_clustering(karate_graph)

get_and_eval_clustering(strike_graph)

# export

import json

def export_graph_json(G, clustering_results, filename="graph_data.json"):
    nodes = [{"id": node, "group": int(clustering_results[node])} for node in G.nodes()]
    edges = [{"from": u, "to": v} for u, v in G.edges()]

    graph_data = {"nodes": nodes, "edges": edges}

    with open(filename, "w") as f:
        json.dump(graph_data, f, indent=4)

clusters = spectral_clustering(strike_graph)
print(clusters)
export_graph_json(strike_graph, clusters, "strike_spectral.json")

from google.colab import files
files.download("strike_spectral.json")

def evaluate_clustering(graph, true_labels, method, method_name):
    predicted_clusters = method(graph, true_labels) if method_name == "CLARE" else method(graph)
    predicted_labels = np.array([predicted_clusters.get(node, -1) for node in graph.nodes()])

    #del?
    if len(predicted_labels) != len(true_labels):
        print(f"Warning: Mismatch in label lengths for {graph.name} ({method_name})")
        print(f"True Labels: {len(true_labels)}, Predicted Labels: {len(predicted_labels)}")
        return 0, 0, 0, 0  # mismatch -> skip (not needed anymore?)

    nmi = normalized_mutual_info_score(true_labels, predicted_labels)
    ari = adjusted_rand_score(true_labels, predicted_labels)
    modularity = compute_modularity(graph, predicted_clusters)
    conductance = compute_conductance(graph, predicted_clusters)

    print(f"{method_name} Clustering on {graph.name}:")
    print(f"  - NMI: {nmi:.4f}")
    print(f"  - ARI: {ari:.4f}")
    print(f"  - Modularity: {modularity:.4f}")
    print(f"  - Conductance: {conductance:.4f}")
    print("====================================")

    return nmi, ari, modularity, conductance

# Evaluating Louvain
for graph, labels, name in real_node_graphs:
    graph.name = name
    subgraph = get_labeled_subgraph(graph, labels)

    # Louvain Clustering
    evaluate_clustering(subgraph, labels, louvain_clustering, "Louvain")

# Evaluating Spectral
for graph, labels, name in real_node_graphs:
    graph.name = name
    subgraph = get_labeled_subgraph(graph, labels)

    # need lcc for spectral
    if nx.is_connected(subgraph):
        spectral_subgraph = subgraph
    else:
        largest_cc = max(nx.connected_components(subgraph), key=len)
        spectral_subgraph = subgraph.subgraph(largest_cc).copy()
        print(f"LCC Size: {len(spectral_subgraph.nodes())}, Label Size: {len(labels)}")
        num_lcc_clusters = len(set(labels[:len(spectral_subgraph.nodes())]))

    lcc_nodes = list(spectral_subgraph.nodes())
    lcc_labels = np.array([labels[n] for n in lcc_nodes])

    num_lcc_clusters = len(set(lcc_labels))  # only count classes in lcc

    evaluate_clustering(
        spectral_subgraph,
        lcc_labels,
        lambda G: spectral_clustering(G, n_clusters=num_lcc_clusters),
        "Spectral"
    )

# Evaluating Girvan-Newman
for graph, labels, name in real_node_graphs:
    graph.name = name
    subgraph = get_labeled_subgraph(graph, labels)

    evaluate_clustering(subgraph, labels, girvan_newman_clustering, "Girvan-Newman")

subgraph = get_labeled_subgraph(pubmed_graph, pubmed_labels)
evaluate_clustering(subgraph, pubmed_labels, girvan_newman_clustering, "Girvan-Newman")

datasets = ["strike_graph", "karate_graph", "sample_polblog", "polbooks_graph", "football_graph"]

modularity = {
    "Louvain": [0.5557, 0.3920, 0.4529, 0.5270, 0.5270],
    "Spectral": [0.5557, 0.4102, 0.0314, 0.5183, 0.5183],
    "Girvan-Newman": [0.5620, 0.3632, 0.2353, 0.5168, 0.5168]
}

conductance = {
    "Louvain": [0.1499, 0.3460, 0.2401, 0.2760, 0.2760],
    "Spectral": [0.1499, 0.2917, 0.6968, 0.2420, 0.2420],
    "Girvan-Newman": [0.1476, 0.2355, 0.5908, 0.2524, 0.2524]
}

x = np.arange(len(datasets))
width = 0.25  # Bar width

fig, ax = plt.subplots(1, 2, figsize=(12, 5))

#  Modularity
ax[0].bar(x - width, modularity["Louvain"], width, label="Louvain")
ax[0].bar(x, modularity["Spectral"], width, label="Spectral")
ax[0].bar(x + width, modularity["Girvan-Newman"], width, label="Girvan-Newman")
ax[0].set_xticks(x)
ax[0].set_xticklabels(datasets, rotation=20)
ax[0].set_title("Modularity Comparison")
ax[0].set_ylabel("Modularity Score")
ax[0].legend()

#  Conductance
ax[1].bar(x - width, conductance["Louvain"], width, label="Louvain")
ax[1].bar(x, conductance["Spectral"], width, label="Spectral")
ax[1].bar(x + width, conductance["Girvan-Newman"], width, label="Girvan-Newman")
ax[1].set_xticks(x)
ax[1].set_xticklabels(datasets, rotation=20)
ax[1].set_title("Conductance Comparison")
ax[1].set_ylabel("Conductance Score")
ax[1].legend()

plt.tight_layout()
plt.show()